In previous sections, we have seen the core of llm which is the multi-head attention layer. Just like a human can't only have a brain, we need hands, feet and many other organs to assembly a whole body.
This is true for llm, it is not enough to have only multi-head attention layer to be powerful, it also need other layers to work together to complete its job, first let's have a whole picture of the 
complete structure of llm like chatgpt:



<img width="938" height="3894" alt="whiteboard_exported_image" src="https://github.com/user-attachments/assets/1303dd28-5ba2-4b94-93a7-a8debbc40014" />
