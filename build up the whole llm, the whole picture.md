In previous sections, we have seen the core of llm which is the multi-head attention layer. Just like a human can't only have a brain, we need hands, feet and many other organs to assembly a whole body.
This is true for llm, it is not enough to have only multi-head attention layer to be powerful, it also need other layers to work together to complete its job, first let's have a whole picture of the 
complete structure of llm like chatgpt:


<img width="1876" height="8396" alt="whiteboard_exported_image (1)" src="https://github.com/user-attachments/assets/aabb2c1e-0af2-41b0-be07-3b5e5e62e0ab" />
